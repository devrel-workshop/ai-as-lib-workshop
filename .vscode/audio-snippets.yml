# Audio section

snippet audio-requirements:
  name: "Audio requirements"
  prefix: "py-01"
  #scope: "python"
  body: | 
    # audio section
    # Gradio to create the application, see https://pypi.org/project/gradio/
    gradio==5.5.0
    # Pydub to manipulate audio files, see https://pypi.org/project/pydub/
    pydub==0.25.1
    # Numpy to do sientific computing with Python
    numpy==2.1.3
    # Manage http requests, see https://pypi.org/project/requests/
    requests==2.32.3

# Text to speech HTTP section

snippet tts-http-model-url:
  name: "TTS model URL"
  prefix: "py-09"
  scope: "python"
  body: | 
    url = "https://nvr-tts-en-us.endpoints.kepler.ai.cloud.ovh.net/api/v1/tts/text_to_audio"

snippet tts-http-bearer:
  name: "TTS bearer"
  prefix: "sol-tts-http-bearer"
  scope: "python"
  body: | 
    headers = {
        "Authorization": f"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}",
    }

snippet tts-http-payload:
  name: "TTS HTTP payload"
  prefix: "py-09"
  scope: "python"
  body: | 
    payload = {
        "encoding": 1,
        "language_code": "en-US",
        "sample_rate_hz": 16000,
        "text": textToTransform,
        "voice_name": "English-US.Female-1",
    }

snippet tts-http-response:
  name: "TTS HTTP response"
  prefix: "py-10"
  scope: "python"
  body: | 
    response = requests.post(url, json=payload, headers=headers)

snippet tts-http-return:
  name: "TTS HTTP return"
  prefix: "py-11"
  scope: "python"
  body: | 
    audio = (16000, np.frombuffer(response.content, dtype=np.int16))

    return audio

snippet tts-http-input:
  name: "TTS HTTP input"
  prefix: "py-12"
  scope: "python"
  body: | 
    input_text = gr.Textbox(
        label="üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø",
    )

snippet tts-http-output:
  name: "TTS HTTP output"
  prefix: "py-13"
  scope: "python"
  body: | 
    output_audio = gr.Audio(
        label="Audio synthesis (.wav)", type="numpy", show_download_button=False
    )

snippet tts-http-demo:
  name: "TTS HTTP demo"
  prefix: "py-14"
  scope: "python"
  body: | 
    demo = gr.Interface(
        fn=text_to_speech, inputs=input_text, outputs=output_audio, allow_flagging="never"
    )

# Speech to text HTTP section

snippet stt-http-model-url:
  name: "STT model URL"
  prefix: "py-02"
  scope: "python"
  body: | 
    url = "https://nvr-asr-en-gb.endpoints.kepler.ai.cloud.ovh.net/api/v1/asr/recognize"

snippet stt-http-bearer:
  name: "STT bearer"
  prefix: "py-03"
  scope: "python"
  body: | 
    headers = {
        "Authorization": f"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}",
    }

snippet stt-http-audio-transform:
  name: "STT HTTP audio tranform"
  prefix: "py-04"
  scope: "python"
  body: | 
    audio_input = AudioSegment.from_file(audio, "wav")
    process_audio_to_wav = audio_input.set_channels(1)
    process_audio_to_wav = process_audio_to_wav.set_frame_rate(16000)
    process_audio_to_wav.export("audio.wav", format="wav")

snippet stt-http-file-to-send:
  name: "STT HTTP file to send"
  prefix: "py-05"
  scope: "python"
  body: | 
    filetoSend = [('audio', open("audio.wav", 'rb'))]


snippet stt-http-response:
  name: "STT HTTP response"
  prefix: "py-06"
  scope: "python"
  body: | 
    response = requests.post(url, files=filetoSend, headers=headers)
    responseToDisplay=''
    if response.status_code == 200:
        # Handle response
        response_data = response.json()
        for alternative in response_data:
            responseToDisplay+=alternative['alternatives'][0]['transcript']
    else:
        print("Error:", response.status_code)
        responseToDisplay='Unable to do the transcription üò≠'
    
    return responseToDisplay

snippet stt-http-input:
  name: "STT HTTP input"
  prefix: "py-07"
  scope: "python"
  body: | 
    input_audio = gr.Audio(
        sources=['upload', 'microphone'],
        type='filepath',
        label="üá´üá∑"
    )

snippet stt-http-demo:
  name: "STT HTTP demo"
  prefix: "py-08"
  scope: "python"
  body: | 
    demo = gr.Interface(
        fn=speechToText,
        inputs=input_audio,
        outputs="text",
        allow_flagging="never"
    )

# Speech to speech

snippet sts-asr-en-url:
  name: "STS asr EN URL"
  prefix: "py-30"
  scope: "python"
  body: | 
    url = "https://nvr-asr-en-gb.endpoints.kepler.ai.cloud.ovh.net/api/v1/asr/recognize"

snippet sts-asr-en-bearer:
  name: "STS asr EN bearer"
  prefix: "py-31"
  scope: "python"
  body: | 
    headers = {
        "Authorization": f"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}",
    }

snippet sts-asr-en-configure:
  name: "STS asr EN configure"
  prefix: "py-32"
  scope: "python"
  body: | 
    audio_input = AudioSegment.from_file(audio, "wav")
    process_audio_to_wav = audio_input.set_channels(1)
    process_audio_to_wav = process_audio_to_wav.set_frame_rate(16000)
    process_audio_to_wav.export("audio.wav", format="wav")

snippet sts-asr-en-call:
  name: "STS asr EN call"
  prefix: "py-33"
  scope: "python"
  body: | 
    # Prepare the file to send to the endpoint
    filetoSend = [("audio", open("audio.wav", "rb"))]

    # Do the POST request and display the transcription
    response = requests.post(url, files=filetoSend, headers=headers)
    responseToDisplay = ""
    if response.status_code == 200:
        # Handle response
        response_data = response.json()
        for alternative in response_data:
            responseToDisplay += alternative["alternatives"][0]["transcript"]
    else:
        print("Error:", response.status_code)
        responseToDisplay = "Unable to do the transcription üò≠"

    return responseToDisplay

snippet sts-translate-url:
  name: "STS translate URL"
  prefix: "py-34"
  scope: "python"
  body: | 
    url = "https://llama-3-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/chat/completions"
    payload = {
        "max_tokens": 512,
        "messages": [
            {
                "content": "Do not add any other words or explicative than the translation requested.",
                "name": "System",
                "role": "system"
            },
            {
                "content": "translate the phrase following sentence in Espagnol: " + english_text,
                "name": "User",
                "role": "user"
            }
        ],
        "model": "Meta-Llama-3_3-70B-Instruct",
        "temperature": 0,
    }

snippet sts-translate-bearer:
  name: "STT translate bearer"
  prefix: "py-35"
  scope: "python"
  body: | 
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}",
    }

snippet sts-translate-call:
  name: "STT translate call"
  prefix: "py-36"
  scope: "python"
  body: | 
    # Send the request to endpoint with text to transform
    response = requests.post(url, json=payload, headers=headers)

    # Return the translation
    text = "‚ùå Noting to translate ‚ùå"
    if response.status_code == 200:
        # Handle response
        response_data = response.json()
        # Parse JSON response
        choices = response_data["choices"]
        for choice in choices:
            text = choice["message"]["content"]
            # Process text and finish_reason
            print(text)
    else:
        print("Error:", response.status_code)
    
    return text

snippet sts-tts-es-url:
  name: "STS tts ES URL"
  prefix: "py-37"
  scope: "python"
  body: | 
    url = "https://nvr-tts-en-us.endpoints.kepler.ai.cloud.ovh.net/api/v1/tts/text_to_audio"

snippet sts-tts-es-bearer:
  name: "STS tts ES bearer"
  prefix: "py-38"
  scope: "python"
  body: | 
    headers = {
        "Authorization": f"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}",
    }

snippet sts-tts-es-payload:
  name: "STS tts ES payload"
  prefix: "py-39"
  scope: "python"
  body: | 
    payload = {
        "encoding": 1,
        "language_code": "es-ES",
        "sample_rate_hz": 16000,
        "text": textToTransform,
        "voice_name": "Spanish-ES-Female-1",
    }

snippet sts-tts-es-call:
  name: "STS tts ES call"
  prefix: "py-40"
  scope: "python"
  body: | 
    response = requests.post(url, json=payload, headers=headers)

    # Return the audio
    # see https://numpy.org/doc/stable/reference/generated/numpy.frombuffer.html
    audio = (16000, np.frombuffer(response.content, dtype=np.int16))

    return audio

snippet sts-final-asr-en-call:
  name: "STS final asr en call"
  prefix: "py-41"
  scope: "python"
  body: | 
    englishText = speechToText(audio)


snippet sts-final-translate-call:
  name: "STS final translate call"
  prefix: "py-42"
  scope: "python"
  body: | 
    spanishText = translate_en_to_spanish(englishText)

snippet sts-final-return:
  name: "STS final return"
  prefix: "py-43"
  scope: "python"
  body: | 
    return [englishText, spanishText, text_to_speech(spanishText)]

snippet sts-input-audio-en:
  name: "STS input audio en"
  prefix: "py-44"
  scope: "python"
  body: | 
    input_audio = gr.Audio(label = "English üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø", sources=["upload", "microphone"], type="filepath")

snippet sts-audio-text-es:
  name: "STS ouput"
  prefix: "py-45"
  scope: "python"
  body: | 
    output_audio = gr.Audio(
      label="Spanish version üá™üá∏", type="numpy", show_download_button=False
    )

snippet sts-demo:
  name: "STS demo"
  prefix: "py-46"
  scope: "python"
  body: | 
    demo = gr.Interface(
    fn=speechToSpeech,
    inputs=input_audio,
    outputs=[gr.Textbox(label="üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø"), gr.Textbox(label="üá™üá∏"), output_audio],
    allow_flagging="never",
    )
