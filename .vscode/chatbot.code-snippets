{
  "Advanced resource ask method": {
    "body": [
      "@Path(\"advanced\")",
      "@POST",
      "public Multi\u003cString\u003e ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service and stream the",
      "  // answer, see https://quarkus.io/guides/getting-started-reactive",
      "  return advancedService.askAQuestion(question);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-11",
    "scope": "java"
  },
  "Chatbot RAG doc loading": {
    "body": [
      "loader = TextLoader(\"./rag-files/conference-information-talk-01.md\")",
      "docs = loader.load()",
      "",
      "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)",
      "splits = text_splitter.split_documents(docs)",
      ""
    ],
    "description": "",
    "prefix": "py-51",
    "scope": "python"
  },
  "Chatbot RAG model": {
    "body": [
      "model = ChatMistralAI(",
      "base_url=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"),",
      "api_key=os.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"),",
      "model=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"),",
      "max_tokens=512,",
      "temperature=0",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-50",
    "scope": "python"
  },
  "Chatbot RAG print": {
    "body": [
      "print(\"ðŸ‘¤: What is the program at AI Summit Barcelona?\")",
      "print(\"ðŸ¤–:\")",
      "for r in rag_chain.stream({\"question\", \"What is the program at AI Summit Barcelona?\"}):",
      "  print(r.content, end=\"\", flush=True)",
      "  time.sleep(0.150)",
      ""
    ],
    "description": "",
    "prefix": "py-55",
    "scope": "python"
  },
  "Chatbot RAG prompt": {
    "body": [
      "rag_chain = (",
      "  {\"context\": vectorstore.as_retriever(), \"question\": RunnablePassthrough()} |",
      "  prompt",
      "  | model",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-54",
    "scope": "python"
  },
  "Chatbot RAG vector DB": {
    "body": [
      "vectorstore = Chroma.from_documents(documents=splits, ",
      "               embedding=OVHCloudEmbeddings(model_name=\"bge-multilingual-gemma2\", ",
      "               access_token=os.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\")))",
      ""
    ],
    "description": "",
    "prefix": "py-52",
    "scope": "python"
  },
  "Chatbot memory LangGraph creation": {
    "body": [
      "workflow = StateGraph(state_schema=MessagesState)",
      ""
    ],
    "description": "",
    "prefix": "py-43",
    "scope": "python"
  },
  "Chatbot memory add memory": {
    "body": [
      "memory = MemorySaver()",
      ""
    ],
    "description": "",
    "prefix": "py-46",
    "scope": "python"
  },
  "Chatbot memory function call": {
    "body": [
      "def call_model(state: MessagesState):",
      "response = model.invoke(",
      "    [SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")] ",
      "    + state[\"messages\"]",
      ")",
      "",
      "return {\"messages\": response.content}",
      ""
    ],
    "description": "",
    "prefix": "py-44",
    "scope": "python"
  },
  "Chatbot memory graph compile": {
    "body": [
      "app = workflow.compile(",
      "checkpointer=memory",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-47",
    "scope": "python"
  },
  "Chatbot memory model": {
    "body": [
      "model = ChatMistralAI(",
      "    base_url=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"),",
      "    api_key=os.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"),",
      "    model=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"),",
      "    max_tokens=512,",
      "    temperature=0",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-42",
    "scope": "python"
  },
  "Chatbot memory model call": {
    "body": [
      "question = \"Hello, my name is StÃ©phane\"",
      "print(f\"ðŸ‘¤: {question}\")",
      "print(\"ðŸ¤–: \")",
      "for message_chunk, metadata in app.stream( ",
      "    {\"messages\": \"Hello, my name is StÃ©phane\"}, config,",
      "    stream_mode=\"messages\",",
      "):",
      "    if message_chunk.content:",
      "        print(message_chunk.content, end=\"\", flush=True)",
      "",
      "question = \"Do you remember my name?\"",
      "print(f\"ðŸ‘¤: {question}\")",
      "print(\"ðŸ¤–: \")",
      "for message_chunk, metadata in app.stream( ",
      "    {\"messages\": \"Do you remember my name?\"}, config,",
      "    stream_mode=\"messages\",",
      "):",
      "    if message_chunk.content:",
      "        print(message_chunk.content, end=\"\", flush=True)",
      ""
    ],
    "description": "",
    "prefix": "py-49",
    "scope": "python"
  },
  "Chatbot memory nodes": {
    "body": [
      "workflow.add_edge(START, \"model\")",
      "workflow.add_node(\"model\", call_model)",
      ""
    ],
    "description": "",
    "prefix": "py-45",
    "scope": "python"
  },
  "Chatbot memory thread ID": {
    "body": [
      "thread_id = uuid.uuid4()",
      "config = {\"configurable\": {\"thread_id\": thread_id}}",
      ""
    ],
    "description": "",
    "prefix": "py-48",
    "scope": "python"
  },
  "Chatbot requirements": {
    "body": [
      "# LangChain dependencies",
      "langchain==0.3.27",
      "langgraph==0.3.27",
      "langchain-mistralai==0.2.11",
      "langchain_chroma==0.2.5",
      "langchain-community==0.3.27",
      ""
    ],
    "description": "",
    "prefix": "py-33",
    "scope": ""
  },
  "Chatbot simple messages": {
    "body": [
      "messages = [",
      "    (",
      "        \"system\",",
      "        \"You are Nestor, a virtual assistant. Answer to the question.\",",
      "    ),",
      "    (\"human\", \"Tell me a joke about Python developers,\"),",
      "]",
      ""
    ],
    "description": "",
    "prefix": "py-35",
    "scope": "python"
  },
  "Chatbot simple model": {
    "body": [
      "model = ChatMistralAI(",
      "    base_url=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"),",
      "    api_key=os.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"),",
      "    model=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"),",
      "    max_tokens=512,",
      "    temperature=0",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-34",
    "scope": "python"
  },
  "Chatbot simple model call": {
    "body": [
      "ai_msg = model.invoke(messages)",
      ""
    ],
    "description": "",
    "prefix": "py-36",
    "scope": "python"
  },
  "Chatbot simple print response": {
    "body": [
      "print(\"ðŸ’¬: Question: Tell me a joke about Python developers\\n\")",
      "print(f\"ðŸ¤–: {ai_msg.content}\")",
      ""
    ],
    "description": "",
    "prefix": "py-37",
    "scope": "python"
  },
  "Chatbot stream call model": {
    "body": [
      "for chunk in model.stream(messages):",
      "  print(chunk.content, end=\"\", flush=True)",
      ""
    ],
    "description": "",
    "prefix": "py-41",
    "scope": "python"
  },
  "Chatbot stream messages": {
    "body": [
      "messages = [",
      "    (",
      "        \"system\",",
      "        \"You are Nestor, a virtual assistant. Answer to the question.\",",
      "    ),",
      "    (\"human\", \"Tell me a joke about Python developers\"),",
      "]",
      ""
    ],
    "description": "",
    "prefix": "py-39",
    "scope": "python"
  },
  "Chatbot stream model": {
    "body": [
      "model = ChatMistralAI(",
      "    base_url=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"),",
      "    api_key=os.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"),",
      "    model=os.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"),",
      "    max_tokens=512,",
      "    temperature=0",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-38",
    "scope": "python"
  },
  "Chatbot stream print": {
    "body": [
      "print(\"ðŸ’¬: Question: Tell me a joke about Python developers\\n\")",
      "print(\"ðŸ¤–:\")",
      ""
    ],
    "description": "",
    "prefix": "py-40",
    "scope": "python"
  },
  "Class annotation advanced": {
    "body": [
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-07",
    "scope": "java"
  },
  "Class annotation advanced resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-09",
    "scope": "java"
  },
  "Class annotation memory": {
    "body": [
      "@ApplicationScoped",
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-12",
    "scope": "java"
  },
  "Class annotation memory resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-14",
    "scope": "java"
  },
  "Class annotation simple": {
    "body": [
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-02",
    "scope": "java"
  },
  "Class annotation simple resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-04",
    "scope": "java"
  },
  "Entry point to llm advanced": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "Multi\u003cString\u003e askAQuestion(String question);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-08",
    "scope": "java"
  },
  "Entry point to llm memory": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "Multi\u003cString\u003e askAQuestion(String question, @MemoryId String memoryId);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-13",
    "scope": "java"
  },
  "Entry point to llm simple": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "String askAQuestion(String question);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-03",
    "scope": "java"
  },
  "Injection advanced resource": {
    "body": [
      "@Inject",
      "AIAdvancedService advancedService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-10",
    "scope": "java"
  },
  "Injection memory resource": {
    "body": [
      "@Inject",
      "AIMemoryService aiMemoryService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-15",
    "scope": "java"
  },
  "Injection simple resource": {
    "body": [
      "@Inject",
      "AISimpleService aiEndpointService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-05",
    "scope": "java"
  },
  "LangChain4j OVHai dependency": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-ovh-ai\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-15",
    "scope": "xml"
  },
  "MCP: AI Services": {
    "body": [
      "@SystemMessage(\"\"\"",
      "        Your are an expert of using the Stable Diffusion XL model.",
      "        The user explains in natural language what kind of image he wants.",
      "        You must do the following steps:",
      "          - Understand the user's request.",
      "          - Generate the two kinds of prompts for stable diffusion: the prompt and the negative prompt",
      "          - the prompts must be in english and detailed and optimized for the Stable Diffusion XL model. ",
      "          - once and only once you have this two prompts call the tool with the two prompts.",
      "        If asked about to create an image, you MUST call the `generateImage` function.",
      "        \"\"\")",
      "@UserMessage(\"Create an image with stable diffusion XL following this description: {{userMessage}}\")",
      "String chat(@V(\"userMessage\") String userMessage);",
      ""
    ],
    "description": "",
    "prefix": "java-33",
    "scope": "java"
  },
  "MCP: call LLM": {
    "body": [
      "String userInput = \"\";",
      "Scanner scanner = new Scanner(System.in);",
      "while (true) {",
      "    _LOG.info(\"\\nEnter your message: \");",
      "    userInput = scanner.nextLine();",
      "    if (userInput.equalsIgnoreCase(\"exit\")) break;",
      "    _LOG.info(\"\\nResponse: \" + bot.chat(userInput));",
      "}",
      "scanner.close();",
      ""
    ],
    "description": "",
    "prefix": "java-40-prompt",
    "scope": "java"
  },
  "MCP: chatbot": {
    "body": [
      "ChatBot bot = AiServices.builder(ChatBot.class)",
      "        .chatModel(chatModel)",
      "        .toolProvider(toolProvider)",
      "        .chatMemory(chatMemory)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-39-chatbot",
    "scope": "java"
  },
  "MCP: dependency": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-mcp\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-32",
    "scope": "xml"
  },
  "MCP: mcp client": {
    "body": [
      "McpClient mcpClient = new DefaultMcpClient.Builder()",
      "        .transport(transport)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-36-mcp-client",
    "scope": "java"
  },
  "MCP: memory": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-38-memory",
    "scope": "java"
  },
  "MCP: model selection": {
    "body": [
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        // To have more deterministic outputs, set temperature to 0.",
      "        .temperature(0.0)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-34",
    "scope": "java"
  },
  "MCP: tool provider": {
    "body": [
      "McpToolProvider toolProvider = McpToolProvider.builder()",
      "        .mcpClients(mcpClient)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-37-mcp-tool",
    "scope": "java"
  },
  "MCP: transport": {
    "body": [
      "McpTransport transport = new HttpMcpTransport.Builder()",
      "        // https://xxxx/mcp/sse",
      "        .sseUrl(System.getenv(\"MCP_SERVER_URL\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-35-mcp-transport",
    "scope": "java"
  },
  "Memory AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-10",
    "scope": "java"
  },
  "Memory assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .chatMemory(chatMemory)",
      "    .build();  ",
      ""
    ],
    "description": "",
    "prefix": "java-13",
    "scope": "java"
  },
  "Memory call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: My name is StÃ©phane.\\n\");",
      "    TokenStream tokenStream = assistant.chat(\"My name is StÃ©phane.\");",
      "    _LOG.info(\"ðŸ¤–: \");",
      "    tokenStream",
      "            .onPartialResponse(_LOG::info)",
      "            .onCompleteResponse(token -\u003e {",
      "                _LOG.info(\"\\nðŸ’¬: Do you remember what is my name?\\n\");",
      "                _LOG.info(\"ðŸ¤–: \");",
      "                assistant.chat(\"Do you remember what is my name?\")",
      "                        .onPartialResponse(_LOG::info)",
      "                        .onError(Throwable::printStackTrace).start();",
      "            })",
      "            .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-14",
    "scope": "java"
  },
  "Memory memory storage": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-12",
    "scope": "java"
  },
  "Memory model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(false)",
      "    .logResponses(false)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-11",
    "scope": "java"
  },
  "Memory resource ask method": {
    "body": [
      "@Path(\"memory\")",
      "@POST",
      "public Multi\u003cString\u003e ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service and stream the",
      "  // answer, see https://quarkus.io/guides/getting-started-reactive",
      "  return aiMemoryService.askAQuestion(question, \"user-one\");",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-16",
    "scope": "java"
  },
  "Quarkus properties": {
    "body": [
      "quarkus.langchain4j.mistralai.base-url=\\${OVH_AI_ENDPOINTS_MODEL_URL}",
      "quarkus.langchain4j.mistralai.api-key=\\${OVH_AI_ENDPOINTS_ACCESS_TOKEN}",
      "quarkus.langchain4j.mistralai.chat-model.max-tokens=512",
      "quarkus.langchain4j.mistralai.chat-model.model-name=\\${OVH_AI_ENDPOINTS_MODEL_NAME}",
      "quarkus.langchain4j.mistralai.log-requests=true",
      "quarkus.langchain4j.mistralai.log-responses=false",
      "quarkus.langchain4j.mistralai.chat-model.temperature=0.2",
      ""
    ],
    "description": "",
    "prefix": "quarkus-01",
    "scope": ""
  },
  "RAG AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-16",
    "scope": "java"
  },
  "RAG assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .chatMemory(chatMemory)",
      "    .contentRetriever(contentRetriever)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-22",
    "scope": "java"
  },
  "RAG call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: What is the program at AI Summit Barcelona?\\n\");",
      "TokenStream tokenStream = assistant.chat(\"What is the program at AI Summit Barcelona?\");",
      "_LOG.info(\"ðŸ¤–: \");",
      "tokenStream",
      "    .onPartialResponse(_LOG::info)",
      "    .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-23",
    "scope": "java"
  },
  "RAG chunk": {
    "body": [
      "DocumentParser documentParser = new TextDocumentParser();",
      "Document document = loadDocument(",
      "    RAGChatbot.class.getResource(\"/rag-files/conference-information-talk-01.md\").getFile(),",
      "    documentParser);",
      "DocumentSplitter splitter = DocumentSplitters.recursive(8000, 50);",
      "",
      "List\u003cTextSegment\u003e segments = splitter.split(document);",
      ""
    ],
    "description": "",
    "prefix": "java-19",
    "scope": "java"
  },
  "RAG embedding": {
    "body": [
      "EmbeddingModel embeddingModel = OvhAiEmbeddingModel.builder()",
      "                .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "                .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_EMBEDDING_MODEL\"))",
      "                .build();",
      "List\u003cEmbedding\u003e embeddings = embeddingModel.embedAll(segments).content();",
      ""
    ],
    "description": "",
    "prefix": "java-20",
    "scope": "java"
  },
  "RAG embedding store": {
    "body": [
      "EmbeddingStore\u003cTextSegment\u003e embeddingStore = new InMemoryEmbeddingStore\u003c\u003e();",
      "embeddingStore.addAll(embeddings, segments);",
      "ContentRetriever contentRetriever = EmbeddingStoreContentRetriever.builder()",
      "    .embeddingStore(embeddingStore)",
      "    .embeddingModel(embeddingModel)",
      "    .maxResults(3)",
      "    .minScore(0.1)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-21",
    "scope": "java"
  },
  "RAG memory": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-18",
    "scope": "java"
  },
  "RAG model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .maxTokens(512)",
      "        .temperature(0.0)",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-17",
    "scope": "java"
  },
  "Simple chatbot AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  String chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-02",
    "scope": "java"
  },
  "Simple chatbot assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .chatModel(chatModel)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-04",
    "scope": "java"
  },
  "Simple chatbot call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: Question: Tell me a joke about Java developers\\n\");",
      "_LOG.info(\"ðŸ¤–: {}\", assistant.chat(\"Tell me a joke about Java developers\"));",
      ""
    ],
    "description": "",
    "prefix": "java-05",
    "scope": "java"
  },
  "Simple chatbot model": {
    "body": [
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(true)",
      "    .logResponses(true)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-03",
    "scope": "java"
  },
  "Simple resource ask method": {
    "body": [
      "@Path(\"simple\")",
      "@POST",
      "public String ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service",
      "  return aiEndpointService.askAQuestion(question);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-06",
    "scope": "java"
  },
  "Streaming AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-06",
    "scope": "java"
  },
  "Streaming assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-08",
    "scope": "java"
  },
  "Streaming call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: Tell me a joke about Java developers\\n\");",
      "TokenStream tokenStream = assistant.chat(\"Tell me a joke about Java developers\");",
      "_LOG.info(\"ðŸ¤–: \");",
      "tokenStream",
      "    .onPartialResponse(_LOG::info)",
      "    .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-09",
    "scope": "java"
  },
  "Streaming model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(false)",
      "    .logResponses(false)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-07",
    "scope": "java"
  },
  "Tool call SDXL": {
    "body": [
      "// Call Stable diffusion model with the prompt and negative prompt",
      "HttpRequest httpRequest = HttpRequest.newBuilder()",
      "        .uri(URI.create(System.getenv(\"OVH_AI_ENDPOINTS_SD_URL\")))",
      "        .POST(HttpRequest.BodyPublishers.ofString(\"\"\"",
      "                    {\"prompt\": \"%s\", ",
      "                      \"negative_prompt\": \"%s\"}",
      "                    \"\"\".formatted(prompt, negativePrompt)))",
      "        .header(\"accept\", \"application/octet-stream\")",
      "        .header(\"Content-Type\", \"application/json\")",
      "        .header(\"Authorization\", \"Bearer \" + System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-25",
    "scope": "java"
  },
  "Tool generateImage tool": {
    "body": [
      "// Define the tool using the @Tool annotation",
      "@Tool(\"\"\"",
      "            Tool to create an image with Stable Diffusion XL given a prompt and a negative prompt.",
      "            \"\"\")",
      "void generateImage(@P(\"Prompt that explains the image\") String prompt, @P(\"Negative prompt that explains what the image must not contains\") String negativePrompt) throws IOException, InterruptedException {",
      "    _LOG.info(\"Prompt: {}\", prompt);",
      "    _LOG.info(\"Negative prompt: {}\", negativePrompt);",
      "",
      "    // java-25",
      "",
      "    // java-26",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-24",
    "scope": "java"
  },
  "Tool: AI Services": {
    "body": [
      "// Create a detailed system prompt: the goal and what the model must generate and use",
      "@SystemMessage(\"\"\"",
      "        Your are an expert of using the Stable Diffusion XL model.",
      "        The user explains in natural language what kind of image he wants.",
      "        You must do the following steps:",
      "          - Understand the user's request.",
      "          - Generate the two kinds of prompts for stable diffusion: the prompt and the negative prompt",
      "          - the prompts must be in english and detailed and optimized for the Stable Diffusion XL model. ",
      "          - once and only once you have this two prompts call the tool with the two prompts.",
      "        If asked about to create an image, you MUST call the `generateImage` function.",
      "        \"\"\")",
      "@UserMessage(\"Create an image with stable diffusion XL following this description: {{userMessage}}\")",
      "String chat(@V(\"userMessage\") String userMessage);",
      ""
    ],
    "description": "",
    "prefix": "java-27",
    "scope": "java"
  },
  "Tool: build chatbot": {
    "body": [
      "// Build the chatbot thanks to LangChain4J AI Services mode (see https://docs.langchain4j.dev/tutorials/ai-services)",
      "ChatBot chatBot = AiServices.builder(ChatBot.class)",
      "        .chatModel(chatModel)",
      "        .tools(new ImageGenTools())",
      "        .chatMemory(chatMemory)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-30",
    "scope": "java"
  },
  "Tool: call LLM": {
    "body": [
      "// Start the conversation loop (enter \"exit\" to quit)",
      "String userInput = \"\";",
      "Scanner scanner = new Scanner(System.in);",
      "while (true) {",
      "    _LOG.info(\"\\nEnter your message: \");",
      "    userInput = scanner.nextLine();",
      "    if (userInput.equalsIgnoreCase(\"exit\")) break;",
      "    _LOG.info(\"\\nResponse: \" + chatBot.chat(userInput));",
      "}",
      "scanner.close();",
      ""
    ],
    "description": "",
    "prefix": "java-31",
    "scope": "java"
  },
  "Tool: memory": {
    "body": [
      "// Add memory to fine tune the SDXL prompt.",
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-29",
    "scope": "java"
  },
  "Tool: model selection": {
    "body": [
      "// Main chatbot configuration, try to be more deterministic as possible ;)",
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        // To have more deterministic outputs, set temperature to 0.",
      "        .temperature(0.0)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-28",
    "scope": "java"
  },
  "Tool: save image": {
    "body": [
      "// Create the image file from Stable Diffusion response",
      "HttpResponse\u003cbyte[]\u003e response = HttpClient.newHttpClient()",
      "        .send(httpRequest, HttpResponse.BodyHandlers.ofByteArray());",
      "",
      "_LOG.debug(\"SDXL status code: {}\", response.statusCode());",
      "Files.write(Path.of(\"generated-image.jpeg\"), response.body());",
      ""
    ],
    "description": "",
    "prefix": "java-26",
    "scope": "java"
  },
  "java LangChain4J dependencies": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      "",
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-mistral-ai\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-01",
    "scope": "xml"
  },
  "quarkus-17-dep-mcp": {
    "body": [
      "\u003cdependency\u003e",
      "    \u003cgroupId\u003eio.quarkiverse.mcp\u003c/groupId\u003e",
      "    \u003cartifactId\u003equarkus-mcp-server-sse\u003c/artifactId\u003e",
      "    \u003cversion\u003e1.2.1\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "quarkus-17",
    "scope": "xml"
  },
  "quarkus-18-prop-mcp": {
    "body": [
      "# MCP configuration",
      "quarkus.rest-client.\"com.ovhcloud.ai.quarkus.chatbot.service.StableDiffusionService\".url=\\${OVH_AI_ENDPOINTS_SD_URL}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-18",
    "scope": ""
  },
  "quarkus-19-svc-sdxl": {
    "body": [
      "@RegisterRestClient",
      "@ClientHeaderParam(name = \"Content-Type\", value = \"application/json\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-19",
    "scope": "java"
  },
  "quarkus-20-call-sdxl": {
    "body": [
      "@POST",
      "@ClientHeaderParam(name = \"Authorization\", value = \"Bearer ${quarkus.langchain4j.mistralai.api-key}\")",
      "byte[] generateImage(SDPayload payload);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-20",
    "scope": "java"
  },
  "quarkus-21-inject-sdxl": {
    "body": [
      "@RestClient",
      "StableDiffusionService stableDiffusionService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-21",
    "scope": "java"
  },
  "quarkus-22-tool": {
    "body": [
      "// Define the tool using the @Tool annotation",
      "@Tool(description = \"Tool to create an image with Stable Diffusion XL given a prompt and a negative prompt.\")",
      "String generateImage(@P(\"Prompt that explains the image\") String prompt, @P(\"Negative prompt that explains what the image must not contains\") String negativePrompt) throws IOException, InterruptedException {",
      "    _LOG.info(\"Prompt: {}\", prompt);",
      "    _LOG.info(\"Negative prompt: {}\", negativePrompt);",
      "",
      "    // quarkus-23",
      "    return \"Image generated\";",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-22",
    "scope": "java"
  },
  "quarkus-23-gen-img": {
    "body": [
      "byte[] image = stableDiffusionService.generateImage(new SDPayload(prompt, negativePrompt));",
      "",
      "Files.write(Path.of(\"generated-image.jpeg\"), image);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-23",
    "scope": "java"
  }
}