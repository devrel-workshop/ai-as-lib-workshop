{
  "Advanced resource ask method": {
    "body": [
      "@Path(\"advanced\")",
      "@POST",
      "public Multi\u003cString\u003e ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service and stream the",
      "  // answer, see https://quarkus.io/guides/getting-started-reactive",
      "  return advancedService.askAQuestion(question);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-11",
    "scope": "java"
  },
  "Class annotation advanced": {
    "body": [
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-07",
    "scope": "java"
  },
  "Class annotation advanced resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-09",
    "scope": "java"
  },
  "Class annotation memory": {
    "body": [
      "@ApplicationScoped",
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-12",
    "scope": "java"
  },
  "Class annotation memory resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-14",
    "scope": "java"
  },
  "Class annotation simple": {
    "body": [
      "@RegisterAiService",
      ""
    ],
    "description": "",
    "prefix": "quarkus-02",
    "scope": "java"
  },
  "Class annotation simple resource": {
    "body": [
      "@Path(\"/chatbot\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-04",
    "scope": "java"
  },
  "Entry point to llm advanced": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "Multi\u003cString\u003e askAQuestion(String question);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-08",
    "scope": "java"
  },
  "Entry point to llm memory": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "Multi\u003cString\u003e askAQuestion(String question, @MemoryId String memoryId);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-13",
    "scope": "java"
  },
  "Entry point to llm simple": {
    "body": [
      "@SystemMessage(\"You are a virtual assistant and your name is Nestor.\")",
      "@UserMessage(\"Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.\")",
      "String askAQuestion(String question);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-03",
    "scope": "java"
  },
  "Injection advanced resource": {
    "body": [
      "@Inject",
      "AIAdvancedService advancedService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-10",
    "scope": "java"
  },
  "Injection memory resource": {
    "body": [
      "@Inject",
      "AIMemoryService aiMemoryService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-15",
    "scope": "java"
  },
  "Injection simple resource": {
    "body": [
      "@Inject",
      "AISimpleService aiEndpointService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-05",
    "scope": "java"
  },
  "LangChain4j OVHai dependency": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-ovh-ai\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-15",
    "scope": "xml"
  },
  "LangChain4j dependency": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      "",
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-mistral-ai\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-01",
    "scope": "xml"
  },
  "Memory call": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-10",
    "scope": "java"
  },
  "Memory memory assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .chatMemory(chatMemory)",
      "    .build();  ",
      ""
    ],
    "description": "",
    "prefix": "java-13",
    "scope": "java"
  },
  "Memory memory call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: My name is StÃ©phane.\\n\");",
      "    TokenStream tokenStream = assistant.chat(\"My name is StÃ©phane.\");",
      "    _LOG.info(\"ðŸ¤–: \");",
      "    tokenStream",
      "            .onPartialResponse(_LOG::info)",
      "            .onCompleteResponse(token -\u003e {",
      "                _LOG.info(\"\\nðŸ’¬: Do you remember what is my name?\\n\");",
      "                _LOG.info(\"ðŸ¤–: \");",
      "                assistant.chat(\"Do you remember what is my name?\")",
      "                        .onPartialResponse(_LOG::info)",
      "                        .onError(Throwable::printStackTrace).start();",
      "            })",
      "            .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-14",
    "scope": "java"
  },
  "Memory memory storage": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-12",
    "scope": "java"
  },
  "Memory model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(false)",
      "    .logResponses(false)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-11",
    "scope": "java"
  },
  "Memory resource ask method": {
    "body": [
      "@Path(\"memory\")",
      "@POST",
      "public Multi\u003cString\u003e ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service and stream the",
      "  // answer, see https://quarkus.io/guides/getting-started-reactive",
      "  return aiMemoryService.askAQuestion(question, \"user-one\");",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-16",
    "scope": "java"
  },
  "Quarkus properties": {
    "body": [
      "quarkus.langchain4j.mistralai.base-url=\\${OVH_AI_ENDPOINTS_MODEL_URL}",
      "quarkus.langchain4j.mistralai.api-key=\\${OVH_AI_ENDPOINTS_ACCESS_TOKEN}",
      "quarkus.langchain4j.mistralai.chat-model.max-tokens=512",
      "quarkus.langchain4j.mistralai.chat-model.model-name=\\${OVH_AI_ENDPOINTS_MODEL_NAME}",
      "quarkus.langchain4j.mistralai.log-requests=true",
      "quarkus.langchain4j.mistralai.log-responses=false",
      "quarkus.langchain4j.mistralai.chat-model.temperature=0.2",
      ""
    ],
    "description": "",
    "prefix": "quarkus-01",
    "scope": ""
  },
  "RAG AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-16",
    "scope": "java"
  },
  "RAG assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .chatMemory(chatMemory)",
      "    .contentRetriever(contentRetriever)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-22",
    "scope": "java"
  },
  "RAG call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: What is the program at Sunny Tech?\\n\");",
      "TokenStream tokenStream = assistant.chat(\"What is the program at Sunny Tech?\");",
      "_LOG.info(\"ðŸ¤–: \");",
      "tokenStream",
      "    .onPartialResponse(_LOG::info)",
      "    .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-23",
    "scope": "java"
  },
  "RAG chunk": {
    "body": [
      "DocumentParser documentParser = new TextDocumentParser();",
      "Document document = loadDocument(",
      "    RAGChatbot.class.getResource(\"/rag-files/conference-information-talk-01.md\").getFile(),",
      "    documentParser);",
      "DocumentSplitter splitter = DocumentSplitters.recursive(8000, 50);",
      "",
      "List\u003cTextSegment\u003e segments = splitter.split(document);",
      ""
    ],
    "description": "",
    "prefix": "java-19",
    "scope": "java"
  },
  "RAG embedding": {
    "body": [
      "EmbeddingModel embeddingModel = OvhAiEmbeddingModel.builder()",
      "                .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "                .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_EMBEDDING_MODEL\"))",
      "                .build();",
      "List\u003cEmbedding\u003e embeddings = embeddingModel.embedAll(segments).content();",
      ""
    ],
    "description": "",
    "prefix": "java-20",
    "scope": "java"
  },
  "RAG embedding store": {
    "body": [
      "EmbeddingStore\u003cTextSegment\u003e embeddingStore = new InMemoryEmbeddingStore\u003c\u003e();",
      "embeddingStore.addAll(embeddings, segments);",
      "ContentRetriever contentRetriever = EmbeddingStoreContentRetriever.builder()",
      "    .embeddingStore(embeddingStore)",
      "    .embeddingModel(embeddingModel)",
      "    .maxResults(3)",
      "    .minScore(0.1)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-21",
    "scope": "java"
  },
  "RAG memory": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-18",
    "scope": "java"
  },
  "RAG model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .maxTokens(512)",
      "        .temperature(0.0)",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-17",
    "scope": "java"
  },
  "Simple chatbot AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  String chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-02",
    "scope": "java"
  },
  "Simple chatbot assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .chatModel(chatModel)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-04",
    "scope": "java"
  },
  "Simple chatbot call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: Question: Tell me a joke about Java developers\\n\");",
      "_LOG.info(\"ðŸ¤–: {}\", assistant.chat(\"Tell me a joke about Java developers\"));",
      ""
    ],
    "description": "",
    "prefix": "java-05",
    "scope": "java"
  },
  "Simple chatbot model": {
    "body": [
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(true)",
      "    .logResponses(true)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-03",
    "scope": "java"
  },
  "Simple resource ask method": {
    "body": [
      "@Path(\"simple\")",
      "@POST",
      "public String ask(String question) {",
      "  // Call the askAQuestion method of the AISimpleService service",
      "  return aiEndpointService.askAQuestion(question);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-06",
    "scope": "java"
  },
  "Streaming AI Services": {
    "body": [
      "interface Assistant {",
      "  @SystemMessage(\"You are Nestor, a virtual assistant. Answer to the question.\")",
      "  TokenStream chat(String message);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-06",
    "scope": "java"
  },
  "Streaming assistant": {
    "body": [
      "Assistant assistant = AiServices.builder(Assistant.class)",
      "    .streamingChatModel(steamingModel)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-08",
    "scope": "java"
  },
  "Streaming call": {
    "body": [
      "_LOG.info(\"ðŸ’¬: Tell me a joke about Java developers\\n\");",
      "TokenStream tokenStream = assistant.chat(\"Tell me a joke about Java developers\");",
      "_LOG.info(\"ðŸ¤–: \");",
      "tokenStream",
      "    .onPartialResponse(_LOG::info)",
      "    .onError(Throwable::printStackTrace).start();",
      ""
    ],
    "description": "",
    "prefix": "java-09",
    "scope": "java"
  },
  "Streaming model": {
    "body": [
      "MistralAiStreamingChatModel steamingModel = MistralAiStreamingChatModel.builder()",
      "    .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "    .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "    .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "    .maxTokens(512)",
      "    .temperature(0.0)",
      "    .logRequests(false)",
      "    .logResponses(false)",
      "    .build();",
      ""
    ],
    "description": "",
    "prefix": "java-07",
    "scope": "java"
  },
  "java-24-Tool": {
    "body": [
      "// Define the tool using the @Tool annotation",
      "@Tool(\"\"\"",
      "            Tool to create an image with Stable Diffusion XL given a prompt and a negative prompt.",
      "            \"\"\")",
      "void generateImage(@P(\"Prompt that explains the image\") String prompt, @P(\"Negative prompt that explains what the image must not contains\") String negativePrompt) throws IOException, InterruptedException {",
      "    _LOG.info(\"Prompt: {}\", prompt);",
      "    _LOG.info(\"Negative prompt: {}\", negativePrompt);",
      "",
      "    // java-25",
      "",
      "    // java-26",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-24",
    "scope": "java"
  },
  "java-25-sdxl-call": {
    "body": [
      "// Call Stable diffusion model with the prompt and negative prompt",
      "HttpRequest httpRequest = HttpRequest.newBuilder()",
      "        .uri(URI.create(System.getenv(\"OVH_AI_ENDPOINTS_SD_URL\")))",
      "        .POST(HttpRequest.BodyPublishers.ofString(\"\"\"",
      "                    {\"prompt\": \"%s\", ",
      "                      \"negative_prompt\": \"%s\"}",
      "                    \"\"\".formatted(prompt, negativePrompt)))",
      "        .header(\"accept\", \"application/octet-stream\")",
      "        .header(\"Content-Type\", \"application/json\")",
      "        .header(\"Authorization\", \"Bearer \" + System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-25",
    "scope": "java"
  },
  "java-26-write-img": {
    "body": [
      "// Create the image file from Stable Diffusion response",
      "HttpResponse\u003cbyte[]\u003e response = HttpClient.newHttpClient()",
      "        .send(httpRequest, HttpResponse.BodyHandlers.ofByteArray());",
      "",
      "_LOG.debug(\"SDXL status code: {}\", response.statusCode());",
      "Files.write(Path.of(\"generated-image.jpeg\"), response.body());",
      ""
    ],
    "description": "",
    "prefix": "java-26",
    "scope": "java"
  },
  "java-27-ai-services": {
    "body": [
      "// Create a detailed system prompt: the goal and what the model must generate and use",
      "@SystemMessage(\"\"\"",
      "        Your are an expert of using the Stable Diffusion XL model.",
      "        The user explains in natural language what kind of image he wants.",
      "        You must do the following steps:",
      "          - Understand the user's request.",
      "          - Generate the two kinds of prompts for stable diffusion: the prompt and the negative prompt",
      "          - the prompts must be in english and detailed and optimized for the Stable Diffusion XL model. ",
      "          - once and only once you have this two prompts call the tool with the two prompts.",
      "        If asked about to create an image, you MUST call the `generateImage` function.",
      "        \"\"\")",
      "@UserMessage(\"Create an image with stable diffusion XL following this description: {{userMessage}}\")",
      "String chat(@V(\"userMessage\") String userMessage);",
      ""
    ],
    "description": "",
    "prefix": "java-27",
    "scope": "java"
  },
  "java-28-model": {
    "body": [
      "// Main chatbot configuration, try to be more deterministic as possible ;)",
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        // To have more deterministic outputs, set temperature to 0.",
      "        .temperature(0.0)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-28",
    "scope": "java"
  },
  "java-29-model": {
    "body": [
      "// Add memory to fine tune the SDXL prompt.",
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-29",
    "scope": "java"
  },
  "java-30-ai-services": {
    "body": [
      "// Build the chatbot thanks to LangChain4J AI Services mode (see https://docs.langchain4j.dev/tutorials/ai-services)",
      "ChatBot chatBot = AiServices.builder(ChatBot.class)",
      "        .chatModel(chatModel)",
      "        .tools(new ImageGenTools())",
      "        .chatMemory(chatMemory)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-30",
    "scope": "java"
  },
  "java-31-prompt": {
    "body": [
      "// Start the conversation loop (enter \"exit\" to quit)",
      "String userInput = \"\";",
      "Scanner scanner = new Scanner(System.in);",
      "while (true) {",
      "    _LOG.info(\"\\nEnter your message: \");",
      "    userInput = scanner.nextLine();",
      "    if (userInput.equalsIgnoreCase(\"exit\")) break;",
      "    _LOG.info(\"\\nResponse: \" + chatBot.chat(userInput));",
      "}",
      "scanner.close();",
      ""
    ],
    "description": "",
    "prefix": "java-31",
    "scope": "java"
  },
  "java-32-dep-mcp": {
    "body": [
      "\u003cdependency\u003e",
      "  \u003cgroupId\u003edev.langchain4j\u003c/groupId\u003e",
      "  \u003cartifactId\u003elangchain4j-mcp\u003c/artifactId\u003e",
      "  \u003cversion\u003e${langchain4j.provider.version}\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "java-32",
    "scope": "xml"
  },
  "java-33-ai-services": {
    "body": [
      "@SystemMessage(\"\"\"",
      "        Your are an expert of using the Stable Diffusion XL model.",
      "        The user explains in natural language what kind of image he wants.",
      "        You must do the following steps:",
      "          - Understand the user's request.",
      "          - Generate the two kinds of prompts for stable diffusion: the prompt and the negative prompt",
      "          - the prompts must be in english and detailed and optimized for the Stable Diffusion XL model. ",
      "          - once and only once you have this two prompts call the tool with the two prompts.",
      "        If asked about to create an image, you MUST call the `generateImage` function.",
      "        \"\"\")",
      "@UserMessage(\"Create an image with stable diffusion XL following this description: {{userMessage}}\")",
      "String chat(@V(\"userMessage\") String userMessage);",
      ""
    ],
    "description": "",
    "prefix": "java-33",
    "scope": "java"
  },
  "java-34-model": {
    "body": [
      "MistralAiChatModel chatModel = MistralAiChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        // To have more deterministic outputs, set temperature to 0.",
      "        .temperature(0.0)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-34",
    "scope": "java"
  },
  "java-35-": {
    "body": [
      "McpTransport transport = new HttpMcpTransport.Builder()",
      "        // https://xxxx/mcp/sse",
      "        .sseUrl(System.getenv(\"MCP_SERVER_URL\"))",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-35-mcp-transport",
    "scope": "java"
  },
  "java-36": {
    "body": [
      "McpClient mcpClient = new DefaultMcpClient.Builder()",
      "        .transport(transport)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-36-mcp-client",
    "scope": "java"
  },
  "java-37": {
    "body": [
      "McpToolProvider toolProvider = McpToolProvider.builder()",
      "        .mcpClients(mcpClient)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-37-mcp-tool",
    "scope": "java"
  },
  "java-38": {
    "body": [
      "ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);",
      ""
    ],
    "description": "",
    "prefix": "java-38-memory",
    "scope": "java"
  },
  "java-39": {
    "body": [
      "ChatBot bot = AiServices.builder(ChatBot.class)",
      "        .chatModel(chatModel)",
      "        .toolProvider(toolProvider)",
      "        .chatMemory(chatMemory)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-39-chatbot",
    "scope": "java"
  },
  "java-40": {
    "body": [
      "String userInput = \"\";",
      "Scanner scanner = new Scanner(System.in);",
      "while (true) {",
      "    _LOG.info(\"\\nEnter your message: \");",
      "    userInput = scanner.nextLine();",
      "    if (userInput.equalsIgnoreCase(\"exit\")) break;",
      "    _LOG.info(\"\\nResponse: \" + bot.chat(userInput));",
      "}",
      "scanner.close();",
      ""
    ],
    "description": "",
    "prefix": "java-40-prompt",
    "scope": "java"
  },
  "quarkus-17-dep-mcp": {
    "body": [
      "\u003cdependency\u003e",
      "    \u003cgroupId\u003eio.quarkiverse.mcp\u003c/groupId\u003e",
      "    \u003cartifactId\u003equarkus-mcp-server-sse\u003c/artifactId\u003e",
      "    \u003cversion\u003e1.2.1\u003c/version\u003e",
      "\u003c/dependency\u003e",
      ""
    ],
    "description": "",
    "prefix": "quarkus-17",
    "scope": "xml"
  },
  "quarkus-18-prop-mcp": {
    "body": [
      "# MCP configuration",
      "quarkus.rest-client.\"com.ovhcloud.ai.quarkus.chatbot.service.StableDiffusionService\".url=\\${OVH_AI_ENDPOINTS_SD_URL}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-18",
    "scope": ""
  },
  "quarkus-19-svc-sdxl": {
    "body": [
      "@RegisterRestClient",
      "@ClientHeaderParam(name = \"Content-Type\", value = \"application/json\")",
      ""
    ],
    "description": "",
    "prefix": "quarkus-19",
    "scope": "java"
  },
  "quarkus-20-call-sdxl": {
    "body": [
      "@POST",
      "@ClientHeaderParam(name = \"Authorization\", value = \"Bearer ${quarkus.langchain4j.mistralai.api-key}\")",
      "byte[] generateImage(SDPayload payload);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-20",
    "scope": "java"
  },
  "quarkus-21-inject-sdxl": {
    "body": [
      "@RestClient",
      "StableDiffusionService stableDiffusionService;",
      ""
    ],
    "description": "",
    "prefix": "quarkus-21",
    "scope": "java"
  },
  "quarkus-22-tool": {
    "body": [
      "// Define the tool using the @Tool annotation",
      "@Tool(description = \"Tool to create an image with Stable Diffusion XL given a prompt and a negative prompt.\")",
      "String generateImage(@P(\"Prompt that explains the image\") String prompt, @P(\"Negative prompt that explains what the image must not contains\") String negativePrompt) throws IOException, InterruptedException {",
      "    _LOG.info(\"Prompt: {}\", prompt);",
      "    _LOG.info(\"Negative prompt: {}\", negativePrompt);",
      "",
      "    // quarkus-23",
      "    return \"Image generated\";",
      "}",
      ""
    ],
    "description": "",
    "prefix": "quarkus-22",
    "scope": "java"
  },
  "quarkus-23-gen-img": {
    "body": [
      "byte[] image = stableDiffusionService.generateImage(new SDPayload(prompt, negativePrompt));",
      "",
      "Files.write(Path.of(\"generated-image.jpeg\"), image);",
      ""
    ],
    "description": "",
    "prefix": "quarkus-23",
    "scope": "java"
  }
}