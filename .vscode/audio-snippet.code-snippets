{
  "Audio requirements": {
    "body": [
      "# audio section",
      "# Gradio to create the application, see https://pypi.org/project/gradio/",
      "gradio==5.31.0",
      "# Pydub to manipulate audio files, see https://pypi.org/project/pydub/",
      "pydub==0.25.1",
      "# Numpy to do sientific computing with Python",
      "numpy==2.1.3",
      "# Manage http requests, see https://pypi.org/project/requests/",
      "requests==2.32.3",
      "# OpenAI client for Whisper",
      "openai==1.97.0",
      ""
    ],
    "description": "",
    "prefix": "py-01",
    "scope": ""
  },
  "STS English audio input": {
    "body": [
      "input_audio = gr.Audio(label = \"English üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\", sources=[\"upload\", \"microphone\"], type=\"filepath\")",
      ""
    ],
    "description": "",
    "prefix": "py-30",
    "scope": "python"
  },
  "STS Gradio interface": {
    "body": [
      "demo = gr.Interface(",
      "fn=speechToSpeech,",
      "inputs=input_audio,",
      "outputs=[gr.Textbox(label=\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\"), gr.Textbox(label=\"üá™üá∏\"), output_audio],",
      "allow_flagging=\"never\",",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-32",
    "scope": "python"
  },
  "STS LLM configuration": {
    "body": [
      "url = f\"{os.getenv('OVH_AI_ENDPOINTS_MODEL_URL')}/chat/completions\"",
      "payload = {",
      "    \"max_tokens\": 512,",
      "    \"messages\": [",
      "        {",
      "            \"content\": \"Do not add any other words or explanations than the translation requested.\",",
      "            \"role\": \"system\"",
      "        },",
      "        {",
      "            \"content\": \"Translate the phrase following sentence in Spanish: \" + english_text,",
      "            \"role\": \"user\"",
      "        }",
      "    ],",
      "    \"model\": f\"{os.getenv('OVH_AI_ENDPOINTS_MODEL_NAME')}\",",
      "    \"temperature\": 0,",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-19",
    "scope": "python"
  },
  "STS OpenAI client configuration": {
    "body": [
      "client = OpenAI(base_url=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_URL'), ",
      "        api_key=os.environ.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN'))",
      ""
    ],
    "description": "",
    "prefix": "py-16",
    "scope": "python"
  },
  "STS RIVA Spanish model URL": {
    "body": [
      "url = os.environ.get('OVH_AI_ENDPOINTS_TTS_MODEL')",
      ""
    ],
    "description": "",
    "prefix": "py-23",
    "scope": "python"
  },
  "STS RIVA bearer": {
    "body": [
      "headers = {",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-24",
    "scope": "python"
  },
  "STS RIVA call": {
    "body": [
      "response = requests.post(url, json=payload, headers=headers)",
      "",
      "# Return the audio",
      "# see https://numpy.org/doc/stable/reference/generated/numpy.frombuffer.html",
      "audio = (16000, np.frombuffer(response.content, dtype=np.int16))",
      "",
      "return audio",
      ""
    ],
    "description": "",
    "prefix": "py-26",
    "scope": "python"
  },
  "STS RIVA payload": {
    "body": [
      "payload = {",
      "    \"encoding\": 1,",
      "    \"language_code\": \"es-ES\",",
      "    \"sample_rate_hz\": 16000,",
      "    \"text\": textToTransform,",
      "    \"voice_name\": \"Spanish-ES-Female-1\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-25",
    "scope": "python"
  },
  "STS Spanish text output": {
    "body": [
      "output_audio = gr.Audio(",
      "  label=\"Spanish version üá™üá∏\", type=\"numpy\", show_download_button=False",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-31",
    "scope": "python"
  },
  "STS call English STT": {
    "body": [
      "englishText = speechToText(audio)",
      ""
    ],
    "description": "",
    "prefix": "py-27",
    "scope": "python"
  },
  "STS call Spanish TTS": {
    "body": [
      "return [englishText, spanishText, text_to_speech(spanishText)]",
      ""
    ],
    "description": "",
    "prefix": "py-29",
    "scope": "python"
  },
  "STS call translation": {
    "body": [
      "spanishText = translate_en_to_spanish(englishText)",
      ""
    ],
    "description": "",
    "prefix": "py-28",
    "scope": "python"
  },
  "STS return transcript": {
    "body": [
      "return transcript",
      ""
    ],
    "description": "",
    "prefix": "py-18",
    "scope": "python"
  },
  "STS transcript with Whisper": {
    "body": [
      "with open(audio, \"rb\") as audio_file:",
      "    # Call Whisper transcription API",
      "    transcript = client.audio.transcriptions.create(",
      "        model=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_MODEL'),",
      "        file=audio_file,",
      "        temperature=0.0,",
      "        response_format=\"text\"",
      "    )",
      ""
    ],
    "description": "",
    "prefix": "py-17",
    "scope": "python"
  },
  "STT Gradio interface": {
    "body": [
      "demo = gr.Interface(",
      "    fn=speechToText,",
      "    inputs=input_audio,",
      "    outputs=\"text\",",
      "    allow_flagging=\"never\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-06",
    "scope": "python"
  },
  "STT LLM bearer": {
    "body": [
      "headers = {",
      "    \"Content-Type\": \"application/json\",",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-20",
    "scope": "python"
  },
  "STT LLM call": {
    "body": [
      "# Send the request to endpoint with text to transform",
      "response = requests.post(url, json=payload, headers=headers)",
      ""
    ],
    "description": "",
    "prefix": "py-21",
    "scope": "python"
  },
  "STT Whisper call": {
    "body": [
      "with open(audio, \"rb\") as audio_file:",
      "    # Call Whisper transcription API",
      "    transcript = client.audio.transcriptions.create(",
      "        model=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_MODEL'),",
      "        file=audio_file,",
      "        temperature=0.0,",
      "        response_format=\"text\"",
      "    )",
      ""
    ],
    "description": "",
    "prefix": "py-03",
    "scope": "python"
  },
  "STT client initialization": {
    "body": [
      "client = OpenAI(base_url=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_URL'), ",
      "            api_key=os.environ.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN'))",
      ""
    ],
    "description": "",
    "prefix": "py-02",
    "scope": "python"
  },
  "STT input-audio": {
    "body": [
      "input_audio = gr.Audio(",
      "    sources=['upload', 'microphone'],",
      "    type='filepath',",
      "    label=\"üéôÔ∏è\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-05",
    "scope": "python"
  },
  "STT return transcript": {
    "body": [
      "return transcript",
      ""
    ],
    "description": "",
    "prefix": "py-04",
    "scope": "python"
  },
  "STT translation return": {
    "body": [
      "# Send the request to endpoint with text to transform",
      "response = requests.post(url, json=payload, headers=headers)",
      "",
      "# Return the translation",
      "text = \"‚ùå Noting to translate ‚ùå\"",
      "if response.status_code == 200:",
      "    # Handle response",
      "    response_data = response.json()",
      "    # Parse JSON response",
      "    choices = response_data[\"choices\"]",
      "    for choice in choices:",
      "        text = choice[\"message\"][\"content\"]",
      "        # Process text and finish_reason",
      "        print(text)",
      "else:",
      "    print(\"Error:\", response.status_code)",
      "",
      "return text",
      ""
    ],
    "description": "",
    "prefix": "py-22",
    "scope": "python"
  },
  "TTS HTTP demo": {
    "body": [
      "demo = gr.Interface(",
      "    fn=text_to_speech, inputs=input_text, outputs=output_audio, allow_flagging=\"never\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-15",
    "scope": "python"
  },
  "TTS HTTP input": {
    "body": [
      "input_text = gr.Textbox(",
      "    label=\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\",",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-13",
    "scope": "python"
  },
  "TTS HTTP output": {
    "body": [
      "output_audio = gr.Audio(",
      "    label=\"Audio synthesis (.wav)\", type=\"numpy\", show_download_button=False",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-14",
    "scope": "python"
  },
  "TTS HTTP payload": {
    "body": [
      "payload = {",
      "    \"encoding\": 1,",
      "    \"language_code\": \"en-US\",",
      "    \"sample_rate_hz\": 16000,",
      "    \"text\": textToTransform,",
      "    \"voice_name\": \"English-US.Female-1\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-10",
    "scope": "python"
  },
  "TTS HTTP response": {
    "body": [
      "response = requests.post(url, json=payload, headers=headers)",
      ""
    ],
    "description": "",
    "prefix": "py-11",
    "scope": "python"
  },
  "TTS HTTP return": {
    "body": [
      "audio = (16000, np.frombuffer(response.content, dtype=np.int16))",
      "",
      "return audio",
      ""
    ],
    "description": "",
    "prefix": "py-12",
    "scope": "python"
  },
  "TTS bearer": {
    "body": [
      "headers = {",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-09",
    "scope": "python"
  },
  "TTS model URL": {
    "body": [
      "url = \"https://nvr-tts-en-us.endpoints.kepler.ai.cloud.ovh.net/api/v1/tts/text_to_audio\"",
      ""
    ],
    "description": "",
    "prefix": "py-08",
    "scope": "python"
  }
}