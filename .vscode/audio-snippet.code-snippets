{
  "AI Services configuration": {
    "body": [
      "interface ChatBot {",
      "    @SystemMessage(\"\"\"",
      "    Do not add any other words or explanations than the translation requested.",
      "    \"\"\")",
      "    @UserMessage(\"Translate the following sentence in Spanish: {{userMessage}}\")",
      "    String chat(String userMessage);",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-53",
    "scope": "java"
  },
  "Audio file input": {
    "body": [
      "Path path = Paths.get(\"../example.wav\");",
      ""
    ],
    "description": "",
    "prefix": "java-50",
    "scope": "java"
  },
  "Audio requirements": {
    "body": [
      "# audio section",
      "# Gradio to create the application, see https://pypi.org/project/gradio/",
      "gradio==5.31.0",
      "# Pydub to manipulate audio files, see https://pypi.org/project/pydub/",
      "pydub==0.25.1",
      "# Numpy to do sientific computing with Python",
      "numpy==2.1.3",
      "# Manage http requests, see https://pypi.org/project/requests/",
      "requests==2.32.3",
      "# OpenAI client for Whisper",
      "openai==1.97.0",
      ""
    ],
    "description": "",
    "prefix": "py-01",
    "scope": ""
  },
  "Call the model": {
    "body": [
      "System.out.println(\"‚è≥ Speech creation...\");",
      "Response response = client.newCall(request).execute();",
      "byte[] audio = response.body().bytes();",
      "System.out.println(\"üéµ Speech created üéµ\");",
      "",
      "return audio;",
      ""
    ],
    "description": "",
    "prefix": "java-48",
    "scope": "java"
  },
  "Configure LLM": {
    "body": [
      "ChatModel model = OpenAiChatModel.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .modelName(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_NAME\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_MODEL_URL\"))",
      "        .temperature(0.0)",
      "        .logRequests(false)",
      "        .logResponses(false)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-54",
    "scope": "java"
  },
  "Javelit Ux": {
    "body": [
      "Jt.title(\"Text to speech exercise\").use();",
      "String englishText = Jt.textArea(\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†ÅøÛ†ÅßÛ†Å¢English text üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\").use();",
      "",
      "if (!englishText.isEmpty()) {",
      "  byte[] textToSpeech = textToSpeech(englishText);",
      "",
      "  Jt.audio(textToSpeech)",
      "      .format(\"audio/wav\")",
      "    .use();",
      "}",
      ""
    ],
    "description": "",
    "prefix": "java-49",
    "scope": "java"
  },
  "OkHttp Client": {
    "body": [
      "OkHttpClient client = new OkHttpClient();",
      ""
    ],
    "description": "",
    "prefix": "java-45",
    "scope": "java"
  },
  "OkHttp client": {
    "body": [
      "OkHttpClient okHttpClient = new OkHttpClient();",
      ""
    ],
    "description": "",
    "prefix": "java-56",
    "scope": "java"
  },
  "OpenAI client configuration": {
    "body": [
      "OpenAIClient client = OpenAIOkHttpClient.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_WHISPER_URL\"))",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-49",
    "scope": "java"
  },
  "OpenAI client initialisation": {
    "body": [
      "OpenAIClient client = OpenAIOkHttpClient.builder()",
      "        .apiKey(System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\"))",
      "        .baseUrl(System.getenv(\"OVH_AI_ENDPOINTS_WHISPER_URL\"))",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-41",
    "scope": "java"
  },
  "Payload": {
    "body": [
      "String payload = \"\"\"",
      "        {",
      "          \"encoding\": 1,",
      "          \"language_code\": \"en-US\",",
      "          \"sample_rate_hz\": 16000,",
      "          \"text\": \"%s\",",
      "          \"voice_name\": \"English-US.Female-1\"",
      "        }",
      "        \"\"\";",
      ""
    ],
    "description": "",
    "prefix": "java-57",
    "scope": "java"
  },
  "RIVA call": {
    "body": [
      "System.out.println(\"‚è≥ Translation creation...\");",
      "Response response = okHttpClient.newCall(request).execute();",
      "Files.write(Path.of(\"translation.wav\"), response.body().bytes());",
      "System.out.println(\"üéµ Translation created üéµ\");"
    ],
    "description": "",
    "prefix": "java-59",
    "scope": "java"
  },
  "RIVA configuration": {
    "body": [
      "RequestBody body = RequestBody.create(String.format(payload, translatedText), MediaType.get(\"application/json; charset=utf-8\"));",
      "Request request = new Request.Builder()",
      "        .url(System.getenv(\"OVH_AI_ENDPOINTS_TTS_MODEL\"))",
      "        .addHeader(\"Authorization\", String.format(\"Bearer %s\", System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\")))",
      "        .header(\"accept\", \"application/octet-stream\")",
      "        .post(body)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-58",
    "scope": "java"
  },
  "RIVA request": {
    "body": [
      "RequestBody body = RequestBody.create(String.format(payload, \"Hello, Wolrd!!\"), MediaType.get(\"application/json; charset=utf-8\"));",
      "Request request = new Request.Builder()",
      "        .url(\"https://nvr-tts-en-us.endpoints.kepler.ai.cloud.ovh.net/api/v1/tts/text_to_audio\")",
      "        .addHeader(\"Authorization\", String.format(\"Bearer %s\", System.getenv(\"OVH_AI_ENDPOINTS_ACCESS_TOKEN\")))",
      "        .header(\"accept\", \"application/octet-stream\")",
      "        .post(body)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-47",
    "scope": "java"
  },
  "STS English audio input": {
    "body": [
      "input_audio = gr.Audio(label = \"English üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\", sources=[\"upload\", \"microphone\"], type=\"filepath\")",
      ""
    ],
    "description": "",
    "prefix": "py-30",
    "scope": "python"
  },
  "STS Gradio interface": {
    "body": [
      "demo = gr.Interface(",
      "fn=speechToSpeech,",
      "inputs=input_audio,",
      "outputs=[gr.Textbox(lines=10, label=\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\"), gr.Textbox(lines=10, label=\"üá™üá∏\"), output_audio],",
      "allow_flagging=\"never\",",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-32",
    "scope": "python"
  },
  "STS LLM configuration": {
    "body": [
      "url = f\"{os.getenv('OVH_AI_ENDPOINTS_MODEL_URL')}/chat/completions\"",
      "payload = {",
      "    \"max_tokens\": 512,",
      "    \"messages\": [",
      "        {",
      "            \"content\": \"Do not add any other words or explanations than the translation requested.\",",
      "            \"role\": \"system\"",
      "        },",
      "        {",
      "            \"content\": \"Translate the phrase following sentence in Spanish: \" + english_text,",
      "            \"role\": \"user\"",
      "        }",
      "    ],",
      "    \"model\": f\"{os.getenv('OVH_AI_ENDPOINTS_MODEL_NAME')}\",",
      "    \"temperature\": 0,",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-19",
    "scope": "python"
  },
  "STS OpenAI client configuration": {
    "body": [
      "client = OpenAI(base_url=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_URL'), ",
      "        api_key=os.environ.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN'))",
      ""
    ],
    "description": "",
    "prefix": "py-16",
    "scope": "python"
  },
  "STS RIVA Spanish model URL": {
    "body": [
      "url = os.environ.get('OVH_AI_ENDPOINTS_TTS_MODEL')",
      ""
    ],
    "description": "",
    "prefix": "py-23",
    "scope": "python"
  },
  "STS RIVA bearer": {
    "body": [
      "headers = {",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-24",
    "scope": "python"
  },
  "STS RIVA call": {
    "body": [
      "response = requests.post(url, json=payload, headers=headers)",
      "",
      "# Return the audio",
      "# see https://numpy.org/doc/stable/reference/generated/numpy.frombuffer.html",
      "audio = (16000, np.frombuffer(response.content, dtype=np.int16))",
      "",
      "return audio",
      ""
    ],
    "description": "",
    "prefix": "py-26",
    "scope": "python"
  },
  "STS RIVA payload": {
    "body": [
      "payload = {",
      "    \"encoding\": 1,",
      "    \"language_code\": \"es-ES\",",
      "    \"sample_rate_hz\": 16000,",
      "    \"text\": textToTransform,",
      "    \"voice_name\": \"Spanish-ES-Female-1\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-25",
    "scope": "python"
  },
  "STS Spanish text output": {
    "body": [
      "output_audio = gr.Audio(",
      "  label=\"Spanish version üá™üá∏\", type=\"numpy\", show_download_button=False",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-31",
    "scope": "python"
  },
  "STS call English STT": {
    "body": [
      "englishText = speechToText(audio)",
      ""
    ],
    "description": "",
    "prefix": "py-27",
    "scope": "python"
  },
  "STS call Spanish TTS": {
    "body": [
      "return [englishText, spanishText, text_to_speech(spanishText)]",
      ""
    ],
    "description": "",
    "prefix": "py-29",
    "scope": "python"
  },
  "STS call translation": {
    "body": [
      "spanishText = translate_en_to_spanish(englishText)",
      ""
    ],
    "description": "",
    "prefix": "py-28",
    "scope": "python"
  },
  "STS return transcript": {
    "body": [
      "return transcript",
      ""
    ],
    "description": "",
    "prefix": "py-18",
    "scope": "python"
  },
  "STS transcript with Whisper": {
    "body": [
      "with open(audio, \"rb\") as audio_file:",
      "    # Call Whisper transcription API",
      "    transcript = client.audio.transcriptions.create(",
      "        model=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_MODEL'),",
      "        file=audio_file,",
      "        temperature=0.0,",
      "        response_format=\"text\"",
      "    )",
      ""
    ],
    "description": "",
    "prefix": "py-17",
    "scope": "python"
  },
  "STT Gradio interface": {
    "body": [
      "demo = gr.Interface(",
      "    fn=speechToText,",
      "    inputs=input_audio,",
      "    outputs=gr.Textbox(lines=10, label=\"Transcription\"),",
      "    allow_flagging=\"never\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-06",
    "scope": "python"
  },
  "STT LLM bearer": {
    "body": [
      "headers = {",
      "    \"Content-Type\": \"application/json\",",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-20",
    "scope": "python"
  },
  "STT LLM call": {
    "body": [
      "# Send the request to endpoint with text to transform",
      "response = requests.post(url, json=payload, headers=headers)",
      ""
    ],
    "description": "",
    "prefix": "py-21",
    "scope": "python"
  },
  "STT Whisper call": {
    "body": [
      "with open(audio, \"rb\") as audio_file:",
      "    # Call Whisper transcription API",
      "    transcript = client.audio.transcriptions.create(",
      "        model=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_MODEL'),",
      "        file=audio_file,",
      "        temperature=0.0,",
      "        response_format=\"text\"",
      "    )",
      ""
    ],
    "description": "",
    "prefix": "py-03",
    "scope": "python"
  },
  "STT client initialization": {
    "body": [
      "client = OpenAI(base_url=os.environ.get('OVH_AI_ENDPOINTS_WHISPER_URL'), ",
      "            api_key=os.environ.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN'))",
      ""
    ],
    "description": "",
    "prefix": "py-02",
    "scope": "python"
  },
  "STT input-audio": {
    "body": [
      "input_audio = gr.Audio(",
      "    sources=['upload', 'microphone'],",
      "    type='filepath',",
      "    label=\"üéôÔ∏è\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-05",
    "scope": "python"
  },
  "STT return transcript": {
    "body": [
      "return transcript",
      ""
    ],
    "description": "",
    "prefix": "py-04",
    "scope": "python"
  },
  "STT translation return": {
    "body": [
      "# Send the request to endpoint with text to transform",
      "response = requests.post(url, json=payload, headers=headers)",
      "",
      "# Return the translation",
      "text = \"‚ùå Noting to translate ‚ùå\"",
      "if response.status_code == 200:",
      "    # Handle response",
      "    response_data = response.json()",
      "    # Parse JSON response",
      "    choices = response_data[\"choices\"]",
      "    for choice in choices:",
      "        text = choice[\"message\"][\"content\"]",
      "        # Process text and finish_reason",
      "        print(text)",
      "else:",
      "    print(\"Error:\", response.status_code)",
      "",
      "return text",
      ""
    ],
    "description": "",
    "prefix": "py-22",
    "scope": "python"
  },
  "TTS HTTP demo": {
    "body": [
      "demo = gr.Interface(",
      "    fn=text_to_speech, inputs=input_text, outputs=output_audio, allow_flagging=\"never\"",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-15",
    "scope": "python"
  },
  "TTS HTTP input": {
    "body": [
      "input_text = gr.Textbox(",
      "    label=\"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø\",",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-13",
    "scope": "python"
  },
  "TTS HTTP output": {
    "body": [
      "output_audio = gr.Audio(",
      "    label=\"Audio synthesis (.wav)\", type=\"numpy\", show_download_button=False",
      ")",
      ""
    ],
    "description": "",
    "prefix": "py-14",
    "scope": "python"
  },
  "TTS HTTP payload": {
    "body": [
      "payload = {",
      "    \"encoding\": 1,",
      "    \"language_code\": \"en-US\",",
      "    \"sample_rate_hz\": 16000,",
      "    \"text\": textToTransform,",
      "    \"voice_name\": \"English-US.Female-1\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-10",
    "scope": "python"
  },
  "TTS HTTP response": {
    "body": [
      "response = requests.post(url, json=payload, headers=headers)",
      ""
    ],
    "description": "",
    "prefix": "py-11",
    "scope": "python"
  },
  "TTS HTTP return": {
    "body": [
      "audio = (16000, np.frombuffer(response.content, dtype=np.int16))",
      "",
      "return audio",
      ""
    ],
    "description": "",
    "prefix": "py-12",
    "scope": "python"
  },
  "TTS bearer": {
    "body": [
      "headers = {",
      "    \"Authorization\": f\"Bearer {os.getenv('OVH_AI_ENDPOINTS_ACCESS_TOKEN')}\",",
      "}",
      ""
    ],
    "description": "",
    "prefix": "py-09",
    "scope": "python"
  },
  "TTS model URL": {
    "body": [
      "url = \"https://nvr-tts-en-us.endpoints.kepler.ai.cloud.ovh.net/api/v1/tts/text_to_audio\"",
      ""
    ],
    "description": "",
    "prefix": "py-08",
    "scope": "python"
  },
  "Transcription": {
    "body": [
      "Transcription transcription =",
      "    client.audio().transcriptions().create(createParams).asTranscription();",
      "System.out.println(\"üìù Transcript generated! üìù\");",
      "return transcription.text();",
      ""
    ],
    "description": "",
    "prefix": "java-43",
    "scope": "java"
  },
  "Whisper configuration": {
    "body": [
      "TranscriptionCreateParams createParams = TranscriptionCreateParams.builder()",
      "        .model(System.getenv(\"OVH_AI_ENDPOINTS_WHISPER_MODEL\"))",
      "        .responseFormat(AudioResponseFormat.TEXT)",
      "        .language(\"en\")",
      "        .file(path)",
      "        .build();",
      ""
    ],
    "description": "",
    "prefix": "java-51",
    "scope": "java"
  },
  "translation": {
    "body": [
      "System.out.println(\"üîÑ Translating text to Spanish...üîÑ\");",
      "ChatBot chatbot = AiServices.create(ChatBot.class, model);",
      "String translatedText = chatbot.chat(transcriptionText);",
      "System.out.println(String.format(\"üá™üá∏ Translated text: %s\", translatedText));",
      ""
    ],
    "description": "",
    "prefix": "java-55",
    "scope": "java"
  }
}